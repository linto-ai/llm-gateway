services:
  llm-gateway:
    build:
      context: .
      dockerfile: Dockerfile
    environment:
      - PYTHONUNBUFFERED=1
      - SERVICE_NAME=LLM_Gateway
      - OPENAI_API_BASE=https://chat.ai.linagora.exaion.com/v1/
      - OPENAI_API_TOKEN
      - HTTP_PORT=8000
      - CONCURRENCY=2
      - TIMEOUT=60
      - SWAGGER_PREFIX=
      - SWAGGER_PATH=../document/swagger_llm_gateway.yml
      - RESULT_DB_PATH=./results.sqlite
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    volumes:
      - ./services:/usr/src/services
      - ./.hydra-conf:/usr/src/.hydra-conf
    networks:
      - llm-network
    ports:
      - 8000:8000
    depends_on:
      - redis
  redis:
    image: redis:latest  
    networks:
      - llm-network
    ports:
      - 6379:6379

networks:
  llm-network: