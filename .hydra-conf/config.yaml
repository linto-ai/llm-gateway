defaults :
  - _self_
  - services :
    - en
    - fr

prompt_path: ./services/
backend_defaults :
  name: null
  modelName: null
  totalContextLength: null
  maxGenerationLength: null
  tokenizerClass: null
  createNewTurnAfter: null
  summaryTurns: null
  maxNewTurns: null
  temperature: null
  top_p: null
  reduceSummary: null
  consolidateSummary: null
  service_name: ${oc.env:SERVICE_NAME,LLM_Gateway}

api_base: ${oc.env:OPENAI_API_BASE,http://localhost:9000/v1}
api_key: ${oc.env:OPENAI_API_TOKEN,EMPTY}
service_port: ${oc.decode:${oc.env:HTTP_PORT,8000}}
workers: ${oc.decode:${oc.env:CONCURRENCY,1}}
timeout: ${oc.decode:${oc.env:TIMEOUT,60}}
debug: false

services_broker: ${oc.env:SERVICES_BROKER,redis://localhost:6379}
broker_pass: ${oc.env:BROKER_PASS,EMPTY}